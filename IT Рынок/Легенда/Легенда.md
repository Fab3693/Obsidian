# Первый проект 
## Дата трудоустройства - дата увольнения: 08.2021-11.2023 
## Должность: Junior Developer
## Название компании: СДЭК. Название проекта: Сервис трекинга посылок

## Описание проекта
### Описание проекта с точки зрения бизнеса:

Проект — корпоративный сервис трекинга посылок, ориентированный на B2B-клиентов и конечных получателей. Команда разработки состояла более чем из трёх Java-разработчиков, системного аналитика, frontend-инженера, инженера DevOps и QA-инженеров; при необходимости подключались интеграторы и техподдержка заказчика. Смежные команды включали продукт-менеджмент, службу поддержки, отдел интеграций (взаимодействие с DHL и Почтой России), аналитиков BI и маркетинга. Методология — Agile (Scrum) с двухнедельными спринтами, ежедневными стендапами, демо и ретроспективами; при ускорении задач использовался Kanban для оперативных инцидентов. Главный заказчик — коммерческий блок логистического партнёра/оператора, конечные потребители — клиенты и получатели посылок. Заявки на разработку обычно приходили от Product Owner и линейного бизнеса, требования формировались в виде бизнес-требований (БТ) с последующим ТЗ и acceptance-критериями от системного аналитика; срочные баг-репорты поступали от службы поддержки и SLA-партнёров. Взаимодействие с заказчиком включало регулярные план-показы, приоритетизацию roadmap и совместное согласование SLA; решения по масштабированию и отказоустойчивости принимались совместно с архитектором и бизнесом. Результатом стала повышенная точность статусов и удовлетворённость. Клиентов.

### Описание проекта с точки зрения архитектуры:

#### Архитектура сервиса трекинга (system design) — подробное описание

Сервис построен как набор независимых микросервисов на Java 11 / Spring Boot, развёрнутых в контейнерах (Kubernetes). Центральная идея — CQRS-подобное разделение: операционная (OLTP) часть — в PostgreSQL, событийная шина — Apache Kafka для интеграций и асинхронной обработки, кэширование — Redis (для горячих запросов и rate-limiting). CI/CD + Testcontainers для интеграционных прогонов.

---

#### СУБД и основные сущности

**Основная СУБД:** PostgreSQL 13 — единый источник правды для бизнес-сущностей.

Примерная структура (≈12–15 таблиц):

- `clients` (B2B-клиенты, контактные данные)
    
- `users` (логины/роли операторов/клиентских админов)
    
- `shipments` / `parcels` (основная сущность отправления: id, external_track, client_id, status, created_at, estimated_delivery)
    
- `shipment_events` (история статусов: shipment_id, status, timestamp, source, payload)
    
- `recipients` / `addresses` (адреса, телефоны)
    
- `carriers` (DHL, Почта России и т.д.)
    
- `integrations_log` (запросы/ответы внешним API)
    
- `phone_index` (индекс для поиска по телефону)
    
- `audit_logs` (операции пользователей)
    
- `configs`, `retry_queue`, `dead_letters`
    

**Размеры (приблизительно, ориентир):**

- `shipments`: 1–10 M записей (зависит от объёма клиентов; для среднего оператора — ~3–5M).
    
- `shipment_events`: 10–50 M записей (каждому отправлению — несколько событий).
    
- `users`, `clients`, `carriers`: <<100k.  
    (Числа оценочные — в реальном проекте — метрики мониторинга и ретеншн задают точные значения.)
    

Дополнительно: **Redis** для кэширования последних состояний треков и сессий; TTL 10–60 минут. Для аналитики возможно выделение реплики PostgreSQL и ETL в отдельный хранилище (например, ClickHouse/OLAP) — данные из Kafka стримятся туда.

---

#### Kafka — топики и схема событий

Kafka используется как событийная шина для асинхронной интеграции, масштабируемой доставки событий и decoupling:

Основные топики:

- `tracking.events` — все изменения статусов (payload: shipment_id, status, timestamp, source).
    
- `tracking.commands` — команды на пересинхронизацию/получение состояния.
    
- `external.dhl.responses`, `external.post.responses` — ответы от интеграций с внешними перевозчиками (внутренние мапперы пишут в них).
    
- `crm.sync` — события для CRM (push статусов клиентов).
    
- `notifications.email`, `notifications.sms` — сообщения для нотификаций.
    
- `dead.letters` — ошибки обработки (DLQ).
    

Формат сообщений — JSON с версионированием в заголовке; при росте команда может ввести Avro + Schema Registry.

---

#### Микросервисы (перечень, взаимодействия и СУБД)

1. **API Gateway**
    
    - Тип: REST (Spring MVC).
        
    - Общается с: Auth, Tracking API (REST), Search (REST).
        
    - Роль: маршрутизация, auth, rate-limit, aggregation.
        
    - БД: нет (stateless).
      
2. **Auth & User Service**
    
    - REST для логина/ролей.
        
    - БД: `users` в PostgreSQL.
        
    - Причина REST: синхронный доступ для UI.
      
3. **Tracking Service (ядро)**
    
    - Обрабатывает запросы по трекам, CRUD отправлений, возвращает current state.
        
    - Общается: с PostgreSQL (shipments, shipment_events) напрямую; публикует события в Kafka `tracking.events` при изменениях; подписывается на `external.*` для обновлений от интеграций.
        
    - Почему: синхронный REST API для UI + асинхронная публикация для downstream.
    
4. **Integration Service (внешние API: DHL, Почта России)**
    
    - Подписан на `tracking.events` / `tracking.commands`; делает запросы к внешним перевозчикам через Spring WebClient; результаты публикует в `external.*` или напрямую в `tracking.events`.
        
    - Хранит логи в `integrations_log` (Postgres).
        
    - Почему Kafka: позволяет масштабировать опросы и повторную обработку, decouple.
    
5. **CRM Sync Service**
    
    - Подписчик `tracking.events`; шлёт агрегированные обновления в CRM через REST; записывает статусы отправки в `integrations_log`.
        
    - Почему: асинхронная интеграция — не блокировать основной поток.
      
6. **Notification Service**
    
    - Подписывается на `tracking.events`, пишет в `notifications.email` / `notifications.sms`; интегрируется с внешними провайдерами (REST).
        
    - Кэш шаблонов в Redis.
      
7. **Search / Query Service**
    
    - Предоставляет сложный поиск (по телефону, фильтры). Использует Spring Data JPA + Criteria API к PostgreSQL; кеширует горячие запросы в Redis.
        
    - Причина REST: быстрый sync отклик для UI.
      
8. **Analytics / ETL**
    
    - Читает `tracking.events` и стримит в OLAP (реплика Postgres / ClickHouse).
        
    - Вычисляет KPI, SLA, задержки.
      
9. **Admin / Batch Worker**
    
    - Обрабатывает retries, dead letters; запускает периодические jobs (например, reconciliation с перевозчиками). Работает через Kafka и DB.
      
---

#### Надёжность и масштабирование

- Идемпотентность: события содержат `event_id` и versioning.
    
- Retry и circuit-breaker: RetryTemplate и Resilience4j.
    
- Горизонтальное масштабирование: stateless-сервисы в K8s, Kafka consumer groups для параллелизма.
    
- Мониторинг: Prometheus + Grafana, лог-центризация (ELK/Graylog).
    

---
## Описание каждого микро-сервиса

### API Gateway / BFF

API Gateway / BFF — это фасад между клиентским приложением (веб/мобильный) и набором бэкенд-микросервисов. Его основная цель — упростить клиенту интерфейс, реализовать кросс-срезовую логику (аутентификация, агрегация, кеш, защиту) и выступать точкой входа для всех запросов.

Откуда берёт данные

- Прямо из внутренних микросервисов по REST (Tracking Service, Search, Auth, Notification, CRM).
    
- Асинхронно — через Kafka для событий/уведомлений (Gateway может подписываться на SSE/WebSocket-канал или получать push от Notification Service).
    
- Быстрые ответы из Redis (кеш последних статусов, сессии, rate counters).
    

Что делает внутри (функционал)

- Аутентификация/авторизация: проверка JWT/OAuth2 токенов (Spring Security), роль-менеджмент, scopes.
    
- Роутинг & трансформация: маршрутизация запросов к соответствующим сервисам, трансформация payload (API-versioning, адаптация полей для клиентов).
    
- Агрегация/композиция: объединяет ответы нескольких сервисов в один API-ответ (например: shipment + lastEvent + estimatedDelivery). Выполняет параллельные REST вызовы и собирает результат.
    
- Кеширование: ответные кеши в Redis с TTL для «горячих» треков; ETag/If-Modified-Since для снижения трафика.
    
- Rate limiting & throttling: token bucket / leaky bucket по API-ключам/пользователям.
    
- Resilience: circuit breaker, retry, fallback (Resilience4j).
    
- Валидация & контракт: входящий запрос валидируется по OpenAPI/JSON Schema; ошибки консолидируются.
    
- Логирование/трейсинг: OpenTelemetry/Zipkin, корреляция requestId, structured logs.
    
- Security hardening: input sanitization, CORS, CSP, IP whitelisting, WAF hooks.
    

Куда отправляет

- Синхронные REST-вызовы к соответствующим сервисам; агрегированные запросы параллельно.
    
- Публикует аналитические события (request/latency/errors) в Kafka/metrics pipeline.
    
- При push-уведомлениях использует WebSocket/SSE канал к клиентам (через Notification Service или напрямую, если BFF держит сессии).
    

Результат: единая, безопасная и производительная точка входа, минимизирующая сложность клиентской логики и уменьшающая число round-trip’ов.

### Auth & User Service
Auth & User Service — это центральный сервис аутентификации и управления пользователями, который обеспечивает безопасность всего трекинг-проекта. Он изолирован от других сервисов, но используется каждым при обращении через API Gateway.

Откуда берёт данные

- Основной источник — таблица `users` в PostgreSQL. Она содержит поля: `id`, `username`, `password_hash`, `email`, `phone`, `role`, `permissions`, `status`, `created_at`.
    
- Дополнительно сервис обращается к таблице `clients` (для B2B-аккаунтов и их администраторов).
    
- Для проверки токенов сессий и ограничения частоты запросов используется Redis (хранение refresh-токенов и blacklist).
    
- Для аудита сервис пишет записи в `audit_logs`.
    

Что делает внутри (функционал)

- **Регистрация/создание пользователей:** добавление новых B2B-клиентов или внутренних операторов. Пароли хэшируются через BCrypt.
    
- **Аутентификация:** проверка логина/пароля, генерация JWT (или OAuth2 access/refresh токенов).
    
- **Авторизация:** проверка ролей и прав доступа (например, клиент может видеть только свои посылки, оператор — все).
    
- **Управление ролями и правами:** выдача/отзыв прав, назначение админов, разграничение доступа по CRUD-операциям.
    
- **Сессии и токены:** хранение refresh-токенов в Redis, поддержка logout (через blacklist), автообновление access-токенов.
    
- **Безопасность:** защита от brute force (rate limiting), блокировка учётки после N неудачных входов, 2FA (через SMS/email сервисы).
    
- **Интеграция с внешними системами:** поддержка SSO (например, через OAuth2/OpenID Connect для корпоративных клиентов).
    
- **Аудит:** запись действий в PostgreSQL (`audit_logs`), логирование в Kafka для BI и мониторинга.
    

Куда отправляет

- Возвращает в API Gateway access/refresh токены.
    
- Передаёт в другие микросервисы сведения об аутентифицированном пользователе через JWT claims (id, role, clientId).
    
- В Kafka публикует события типа `user.created`, `user.blocked`, `user.roleChanged`.
    
- В `audit_logs` пишет действия пользователей (login, logout, изменение профиля).
    

**Итог:** сервис является ядром безопасности: проверяет идентичность, управляет ролями, ограничивает доступ и формирует событийный след для мониторинга.
### Tracking Service (ядро)
Tracking Service — это центральный микросервис системы, который отвечает за хранение и обработку всех данных, связанных с посылками и их статусами. Он является «источником истины» (system of record) для сущностей доставки и выступает основой для остальных сервисов.

Откуда берёт данные

- **PostgreSQL** — таблицы `shipments`, `shipment_events`, `recipients`, `addresses`. Именно здесь хранится текущее состояние и история каждой посылки.
    
- **Kafka** — топики `external.dhl.responses`, `external.post.responses`, откуда приходят новые статусы от Integration Service.
    
- **API Gateway** — получает REST-запросы от клиентов (через фронтенд или мобильное приложение).
    
- **Redis** — кэш последних статусов для ускорения выдачи популярных запросов.
    

Что делает внутри (функционал)

- **CRUD-операции над отправлениями:** создание записей о новых посылках, обновление информации, закрытие/удаление.
    
- **Обновление статусов:** получение новых событий (через Kafka), их валидация, сохранение в `shipment_events` и обновление «текущего статуса» в `shipments`.
    
- **Агрегация информации:** при запросе клиента сервис собирает данные о посылке, последнем статусе, прогнозируемой дате доставки и контактных данных получателя.
    
- **Поиск:** поддержка фильтров по дате, статусу, клиенту и поиск по телефону (через Criteria API).
    
- **Валидация и нормализация:** проверка формата данных, идемпотентность событий (по `event_id`), обработка конфликтов версий.
    
- **Бизнес-правила:** логика расчёта SLA, определение просрочек, формирование бизнес-ивентов (например, «посылка задержана»).
    
- **API-слой:** предоставляет REST-эндпоинты для BFF (например, `/shipments/{id}`, `/shipments/search`).
    

Куда отправляет

- **Kafka (`tracking.events`)** — публикация новых или обновлённых статусов, которые используются CRM, Notification Service и аналитикой.
    
- **PostgreSQL** — запись состояния и истории посылок.
    
- **API Gateway** — отдаёт REST-ответы клиентам (агрегированные данные по отправлению).
    
- **Redis** — обновляет кэш последних статусов.
    
- **Monitoring** — метрики по скорости обработки событий, количеству запросов, SLA-достижениям.
    

**Итог:** Tracking Service — ядро системы, в котором сходятся все потоки данных: клиенты читают из него статусы, интеграции пишут в него события, а остальные сервисы полагаются на его консистентность.
### Integration Service (внешние API: DHL, Почта России)
Integration Service отвечает за взаимодействие с внешними логистическими операторами (DHL, Почта России и др.) и является критическим звеном между внутренним ядром системы и внешними системами доставки. Он изолирует бизнес-логику от специфики интеграций, что упрощает поддержку и масштабирование.

Откуда берёт данные

- Подписывается на Kafka-топики `tracking.commands` (команды на обновление статусов) и `tracking.events` (новые внутренние события, требующие проверки у перевозчиков).
    
- Из PostgreSQL берёт настройки интеграций (`carriers`, `integrations_log`, retry-очередь).
    
- Может использовать Redis для временного хранения токенов/ключей доступа к внешним API.
    

Что делает внутри (функционал)

- **Обращение к внешним API:** выполняет REST-запросы к системам DHL и Почты России через Spring WebClient. Поддерживает авторизацию (API-ключи, OAuth2, токены).
    
- **Нормализация данных:** каждая система возвращает разный формат событий, поэтому сервис приводит их к унифицированной DTO-модели (MapStruct + internal schema).
    
- **Обработка ошибок:** реализованы retries (Spring Retry/RetryTemplate), отложенные запросы и circuit breaker (Resilience4j). При неудаче событие отправляется в `dead.letters`.
    
- **Логирование:** каждый вызов фиксируется в `integrations_log` (время, payload, статус). Это помогает как для отладки, так и для SLA-отчётов.
    
- **Идемпотентность:** события маркируются `external_event_id`, чтобы избежать повторной обработки одного и того же статуса.
    
- **Расписание:** сервис может запускать периодические batch-запросы (например, ночное обновление треков за последние 24 часа).
    

Куда отправляет

- В Kafka (`external.dhl.responses`, `external.post.responses`) публикует нормализованные ответы.
    
- В Kafka (`tracking.events`) отправляет новые статусы, пригодные для ядра Tracking Service.
    
- В PostgreSQL пишет логи вызовов и результаты в `integrations_log`.
    
- В Monitoring (Prometheus/Grafana) — метрики по SLA, ошибкам, задержкам.
    

**Итог:** Integration Service — связующее звено, которое берёт команды из системы, получает статусы у перевозчиков, нормализует их и передаёт в основной поток событий, гарантируя стабильность и единый формат данных.
### CRM Sync Service
CRM Sync Service — это специализированный микросервис, отвечающий за синхронизацию данных о статусах посылок с внутренней CRM-системой компании. Его задача — автоматизировать обновление клиентских карточек и устранить необходимость ручного ввода информации о доставках.

Откуда берёт данные

- **Kafka (`tracking.events`)** — основное место получения информации. Все изменения статусов посылок, зафиксированные в Tracking Service, транслируются сюда.
    
- **PostgreSQL (`integrations_log`)** — хранит историю синхронизаций и статусы их выполнения (успешно, ошибка, повторная попытка).
    
- **CRM API (внешнее)** — используется для валидации текущего состояния и проверки, требуется ли обновление.
    

Что делает внутри (функционал)

- **Подписка на события:** слушает Kafka-топики с новыми статусами.
    
- **Трансформация данных:** конвертирует событие в формат, который ожидает CRM (обычно REST DTO с полями `clientId`, `shipmentId`, `status`, `timestamp`).
    
- **Идемпотентность:** проверяет, не было ли уже отправлено событие с тем же идентификатором (`event_id`) в CRM, чтобы избежать дублирования.
    
- **Обработка ошибок:** при недоступности CRM сервис откладывает отправку и сохраняет задачу в retry-очередь; при превышении лимита попыток пишет событие в `dead.letters`.
    
- **Логирование:** фиксирует в `integrations_log` дату отправки, payload, результат (успех/ошибка).
    
- **Безопасность:** все запросы в CRM подписываются сервисным токеном/ключом.
    
- **Мониторинг SLA:** считает процент успешных синхронизаций и задержки между событием и записью в CRM.
    

Куда отправляет

- **CRM API:** отправляет обновления статусов и событий доставки (REST-запросы).
    
- **PostgreSQL:** сохраняет логи вызовов, результаты синхронизации и данные о retry.
    
- **Kafka (`crm.sync`)** — публикует события о результатах синхронизации (успех/ошибка) для последующего анализа и мониторинга.
    
- **Monitoring (Prometheus/Grafana):** метрики синхронизации и алерты о сбоях.
    

**Итог:** CRM Sync Service гарантирует, что CRM всегда отображает актуальные статусы посылок, облегчает работу менеджеров и повышает качество обслуживания клиентов.
### Notification Service
Notification Service — это микросервис, отвечающий за доставку уведомлений клиентам и получателям посылок. Его основная цель — обеспечить своевременное информирование о ключевых изменениях (новый статус, прибытие в сортировочный центр, доставка, задержка). Сервис поддерживает несколько каналов коммуникации: email, SMS, push-уведомления.

Откуда берёт данные

- **Kafka (`tracking.events`)** — основной источник, содержащий события об изменении статусов посылок.
    
- **PostgreSQL (`templates`, `notification_logs`)** — хранит шаблоны сообщений для разных каналов и историю отправок.
    
- **Redis** — используется для кэширования шаблонов и временных данных (например, частота уведомлений для одного получателя, чтобы избежать спама).
    
- **API Gateway / BFF** — запросы на ручную отправку уведомлений (например, подтверждение email или reset пароля).
    

Что делает внутри (функционал)

- **Подписка на события:** получает статусы о посылках, определяет, нужно ли уведомлять клиента (например, при смене статуса на «доставлено» или «задержка»).
    
- **Персонализация:** подставляет данные в шаблон (имя клиента, трек-номер, дата доставки).
    
- **Форматирование сообщений:** генерирует текст или HTML-письмо, готовит payload для SMS или push.
    
- **Канальная маршрутизация:** выбирает подходящий канал уведомления в зависимости от предпочтений клиента (email/SMS/push).
    
- **Обработка ошибок:** повторная отправка при сбое (RetryTemplate), запись в DLQ (`dead.letters`) при превышении лимита.
    
- **Логирование:** фиксирует все отправки в `notification_logs` с полями: `shipmentId`, `recipient`, `channel`, `status`, `timestamp`.
    
- **Rate limiting:** защита от избыточной рассылки (ограничение количества уведомлений в сутки для одного пользователя).
    

Куда отправляет

- **Внешние сервисы:**
    
    - Email-провайдер (SMTP/REST API).
        
    - SMS-шлюз (REST).
        
    - Push-сервисы (Firebase, APNS).
        
- **PostgreSQL:** запись истории уведомлений и статуса отправки.
    
- **Kafka (`notifications.email`, `notifications.sms`)** — публикация сообщений для дальнейшей обработки worker-подсистемами.
    
- **Monitoring (Prometheus/Grafana):** метрики по доставляемости, задержкам, ошибкам.
    

**Итог:** Notification Service автоматизирует информирование клиентов, снижает нагрузку на поддержку и повышает прозрачность логистики для конечных пользователей.
### Search / Query Service
Search Service — это микросервис, отвечающий за быстрый и удобный поиск посылок и связанных с ними данных. Его задача — предоставить пользователям (как клиентам, так и операторам) гибкий механизм поиска по различным параметрам: номеру трека, телефону получателя, дате отправки, статусу и другим критериям.

---

Откуда берёт данные

- **PostgreSQL** — основная база данных, таблицы `shipments`, `shipment_events`, `recipients`, `addresses`. Именно отсюда Search Service получает всю необходимую информацию.
    
- **Redis** — кэш для результатов частых поисковых запросов (например, повторные проверки одного и того же трек-номера).
    
- **Kafka (`tracking.events`)** — сервис подписан на поток событий, чтобы оперативно обновлять индексы поиска при изменении статуса посылки.
    

---

Что делает внутри (функционал)

- **Фильтрация и сортировка:** поддерживает поиск по дате, статусу, клиенту, телефону получателя. Использует Spring Data JPA + Criteria API для построения сложных запросов.
    
- **Поиск по телефону:** индексирует номера получателей в отдельной таблице (`phone_index`), что ускоряет выдачу при частых запросах без трек-номера.
    
- **Полнотекстовый поиск:** при необходимости использует расширения PostgreSQL (GIN/TSVector) для поиска по адресу или ФИО.
    
- **Агрегация:** возвращает вместе с результатом ключевые атрибуты посылки: последний статус, дату отправки, прогнозируемую дату доставки.
    
- **Кэширование:** сохраняет результаты популярных запросов в Redis (например, топ-10 последних посылок клиента).
    
- **Обновление индексов:** при поступлении новых событий из Kafka обновляет записи в БД и кэше, чтобы поиск всегда был актуальным.
    
- **Безопасность:** учитывает авторизацию пользователя (через JWT claims), ограничивая видимость данных (например, клиент видит только свои отправления).
    

---

Куда отправляет

- **API Gateway / BFF:** возвращает результаты поиска по REST в агрегированном виде для фронтенда.
    
- **PostgreSQL:** выполняет запросы и обновляет индексы.
    
- **Redis:** пишет и обновляет кэшированные результаты.
    
- **Monitoring:** публикует метрики поиска (время ответа, количество найденных записей, кэш-хиты).
    

---

**Итог:** Search Service обеспечивает быстрый, гибкий и безопасный доступ к данным о посылках. Благодаря индексации и кэшированию он выдерживает высокую нагрузку и ускоряет работу конечных пользователей.
### Analytics / ETL
Analytics / ETL Service — это микросервис (или связка сервисов), который отвечает за сбор, преобразование и загрузку данных из транзакционной части системы в аналитическое хранилище. Его основная цель — предоставить бизнесу актуальные отчёты и дашборды по доставке, SLA, загрузке курьеров и удовлетворённости клиентов.

---

Откуда берёт данные

- **Kafka (`tracking.events`)** — основной источник, содержащий все статусы посылок. Это поток событий, из которого ETL формирует аналитические витрины.
    
- **PostgreSQL (OLTP)** — таблицы `shipments`, `shipment_events`, `clients`, `carriers`. Используется для начальной загрузки и периодических сверок.
    
- **Integrations_log** — для анализа качества интеграций с внешними перевозчиками (ошибки, задержки).
    

---

Что делает внутри (функционал)

- **Extract (извлечение):** подписывается на Kafka и забирает все новые события о посылках. Дополнительно по расписанию выгружает «bulk-данные» из PostgreSQL (например, раз в сутки для проверки консистентности).
    
- **Transform (преобразование):**
    
    - Нормализует данные (объединяет статусы из разных перевозчиков в единый формат).
        
    - Добавляет бизнес-атрибуты (например, метка SLA — выполнено/не выполнено).
        
    - Агрегирует данные по клиентам, регионам, перевозчикам.
        
    - Обогащает данными о времени доставки, причинах задержек, количестве обращений в поддержку.
        
- **Load (загрузка):** пишет подготовленные данные в аналитическую СУБД (часто это **ClickHouse** или отдельная реплика PostgreSQL/Greenplum).
    
- **ETL-пайплайны:** выполняются батчево (ежедневная агрегация) и стримингово (почти реальное время).
    
- **Очистка и ретеншн:** удаляет устаревшие данные из промежуточных таблиц, архивирует сырые логи.
    

---

Куда отправляет

- **Аналитическое хранилище (ClickHouse / PostgreSQL-реплика):** для BI-систем и аналитических отчётов.
    
- **BI-платформы (Power BI, Grafana, Metabase):** дашборды для бизнеса (скорость доставки, SLA, топ клиентов, проблемные регионы).
    
- **Kafka (`analytics.reports`)** — публикация агрегированных событий (например, «доставлено с опозданием»).
    
- **Monitoring (Prometheus/Grafana):** метрики выполнения ETL (время обработки, количество загруженных записей, ошибки).
    

---

**Итог:** Analytics / ETL Service превращает поток «сырых» событий в структурированные аналитические данные. Он обеспечивает бизнес отчётами в реальном времени, помогает оценивать SLA и находить узкие места в логистике, что напрямую влияет на стратегические решения компании.

### Admin / Batch Worker
Admin / Batch Worker Service

Admin / Batch Worker — это служебный микросервис, который отвечает за выполнение фоновых задач, плановых джобов и административных операций в системе. Его главная роль — разгрузить ядро (Tracking Service) и интеграционные сервисы от тяжёлых или периодических вычислений, которые не требуют мгновенной реакции.

---

Откуда берёт данные

- **PostgreSQL** — таблицы `shipments`, `shipment_events`, `integrations_log`, `retry_queue`, `dead_letters`.
    
- **Kafka (`dead.letters`, `tracking.events`)** — подписывается на «проблемные» события для повторной обработки и сверки.
    
- **Конфигурации (configs)** — отдельная таблица в БД или YAML-файлы с расписаниями и настройками джобов.
    

---

Что делает внутри (функционал)

- **Retry обработка:** периодически проверяет `retry_queue` и `dead_letters`, повторно пытается отправить события в Tracking Service, CRM или Notification Service.
    
- **Batch-запросы:** раз в N часов запускает массовые сверки — например, проверяет все посылки в статусе «в пути» дольше 10 дней и запрашивает актуальный статус у перевозчика.
    
- **Архивация:** переносит устаревшие данные из `shipment_events` в архивные таблицы или внешнее хранилище, чтобы разгрузить OLTP.
    
- **Очистка данных:** удаляет временные записи, очищает кэш или старые retry-записи.
    
- **Мониторинг SLA:** формирует отчёты о задержках (например, «20% посылок клиента X просрочены»).
    
- **Админ-функции:** обработка ручных команд от операторов (например, «перезапустить синхронизацию для клиента А»).
    
- **Планировщик:** использует Quartz/Spring Scheduler для запуска джобов по cron-расписанию.
    
- **Resilience:** все операции выполняются с retry, логированием и идемпотентностью, чтобы избежать дубликатов.
    

---

Куда отправляет

- **Kafka (`tracking.events`, `crm.sync`, `notifications.*`)** — публикует результаты повторной обработки.
    
- **PostgreSQL (`integrations_log`, `audit_logs`)** — сохраняет отчёты о выполненных задачах.
    
- **Monitoring (Prometheus/Grafana):** отправляет метрики по статусу джобов (успешные/ошибки, время выполнения).
    
- **Админ-интерфейсы:** через REST API предоставляет операторам доступ к управлению задачами (например, повторный запуск).
    

---

**Итог:** Admin / Batch Worker Service обеспечивает «хозяйственную» часть системы — обрабатывает ошибки, повторно запускает процессы, чистит и архивирует данные. Он повышает надёжность всей архитектуры и снижает нагрузку на критичные микросервисы.

## Описание каждого достижения по STAR
### Реализовал личный кабинет клиента с возможностью отслеживания нескольких посылок одновременно.
#### Situation

Компания запускала личный кабинет для клиентов, но изначально там можно было проверять только одну посылку за раз. Это снижало удобство и заставляло пользователей уходить в сторонние сервисы.

#### Task

Необходимо было реализовать интерфейс и backend-логику, позволяющую клиенту авторизоваться и отслеживать сразу несколько посылок одновременно, с быстрым доступом к их статусам.

#### Action

Я разработал REST-контроллер в Spring MVC, который принимал список трек-номеров, обращался к БД через Spring Data JPA и возвращал агрегированный ответ. В PostgreSQL оптимизировал запросы с помощью `IN` и индексов по `tracking_number`. Для фронтенда — единый DTO со статусами.

Пример кода контроллера:

```java
@RestController
@RequestMapping("/api/shipments")
public class ShipmentController {
    private final ShipmentRepository shipmentRepository;

    public ShipmentController(ShipmentRepository shipmentRepository) {
        this.shipmentRepository = shipmentRepository;
    }

    @PostMapping("/track")
    public List<ShipmentDto> trackShipments(@RequestBody List<String> trackingNumbers) {
        return shipmentRepository.findByTrackingNumberIn(trackingNumbers)
                .stream()
                .map(ShipmentMapper::toDto)
                .toList();
    }
}
```

Репозиторий:

```java
public interface ShipmentRepository extends JpaRepository<Shipment, Long> {
    List<Shipment> findByTrackingNumberIn(List<String> trackingNumbers);
}
```

#### Result

Пользователи получили возможность отслеживать сразу несколько отправлений в личном кабинете. Среднее время сессии увеличилось на ~25%, снизилось количество уходов на сторонние трек-сервисы, что улучшило удержание клиентов.

---
### Интегрировал сервис с системой расчета доставки.
#### Situation

Клиенты могли видеть только текущий статус посылки, но не имели информации о прогнозируемой дате доставки. Это снижало прозрачность и увеличивало нагрузку на колл-центр.

#### Task

Необходимо было интегрировать сервис трекинга с системой расчёта доставки, чтобы клиент в личном кабинете видел не только статус, но и прогнозируемую дату получения.

#### Action

Я реализовал интеграцию через **REST API** стороннего сервиса расчёта. Использовал **Spring WebClient** для асинхронных запросов и **MapStruct** для маппинга DTO. Данные кэшировались в PostgreSQL, чтобы снизить нагрузку на внешний сервис.

Пример кода:

```java
@Service
public class DeliveryCalculatorClient {
    private final WebClient webClient;

    public DeliveryCalculatorClient(WebClient.Builder builder) {
        this.webClient = builder.baseUrl("https://delivery-system/api").build();
    }

    public DeliveryInfoDto calculate(String trackingNumber) {
        return webClient.get()
                .uri("/estimate/{trackingNumber}", trackingNumber)
                .retrieve()
                .bodyToMono(DeliveryInfoDto.class)
                .block();
    }
}
```

#### Result

Теперь клиенты видели прогнозируемую дату доставки рядом со статусом посылки. Это сократило количество звонков в поддержку примерно на **20%** и повысило доверие к сервису.
### Реализовал поиск посылки по телефону получателя.
#### Situation

Многие клиенты теряли трек-номер и не могли отследить посылку. Это вызывало рост обращений в поддержку и замедляло процесс поиска отправлений.

#### Task

Необходимо было добавить функционал поиска посылок по номеру телефона получателя, чтобы клиенты могли быстро находить свои отправления без знания трек-номера.

#### Action

Я расширил репозиторий Spring Data JPA, добавив метод поиска по номеру телефона с использованием **Criteria API**. Для повышения производительности в PostgreSQL был создан индекс на колонку `recipient_phone`. В контроллере реализовал REST-метод, возвращающий список всех посылок по указанному номеру.

Пример кода:

```java
public interface ShipmentRepository extends JpaRepository<Shipment, Long>, JpaSpecificationExecutor<Shipment> {
    List<Shipment> findByRecipientPhone(String phone);
}

@RestController
@RequestMapping("/api/shipments")
public class ShipmentController {
    private final ShipmentRepository repository;

    public ShipmentController(ShipmentRepository repository) {
        this.repository = repository;
    }

    @GetMapping("/by-phone/{phone}")
    public List<ShipmentDto> findByPhone(@PathVariable String phone) {
        return repository.findByRecipientPhone(phone)
                .stream()
                .map(ShipmentMapper::toDto)
                .toList();
    }
}
```

#### Result

Функция позволила клиентам находить свои посылки без трек-номера. Количество обращений в поддержку снизилось на **15%**, а скорость самостоятельного поиска отправлений значительно выросла.
### Интегрировал сервис с API DHL и Почты России через Spring WebClient
#### Situation

Сервис трекинга поддерживал только внутренние отправления. Клиенты, ожидавшие посылки через DHL и Почту России, не могли отслеживать их в личном кабинете, что снижало ценность продукта.

#### Task

Необходимо было интегрировать трекинг-сервис с API DHL и Почты России, чтобы клиенты могли видеть единый список всех своих отправлений и статусов, независимо от перевозчика.

#### Action

Я реализовал интеграцию через **Spring WebClient**, добавив адаптеры под разные форматы API. Для обработки ошибок использовал **RetryTemplate** (повторные запросы при временных сбоях) и **Circuit Breaker** для предотвращения перегрузки. Ответы внешних API приводились к единой DTO-модели через **MapStruct**, затем сохранялись в PostgreSQL и публиковались в Kafka-топик `tracking.events`.

Пример кода:

```java
@Service
public class DhlClient {
    private final WebClient webClient;

    public DhlClient(WebClient.Builder builder) {
        this.webClient = builder.baseUrl("https://api.dhl.com/track").build();
    }

    public Mono<ShipmentDto> getShipmentStatus(String trackingNumber) {
        return webClient.get()
                .uri("/{id}", trackingNumber)
                .retrieve()
                .bodyToMono(ShipmentDto.class);
    }
}
```

#### Result

После интеграции клиенты получили возможность отслеживать международные посылки вместе с внутренними. Доля обращений в поддержку по международным отправлениям снизилась на **30%**, а общее удовлетворение сервисом выросло.
### Интегрировал сервис с внутренней CRM через REST API и DTO-модель
#### Situation

До интеграции с CRM статусы доставки клиентов приходилось обновлять вручную, что занимало время у операторов и приводило к ошибкам в данных.

#### Task

Необходимо было автоматизировать передачу статусов из трекинг-сервиса во внутреннюю CRM, чтобы сократить ручную работу и повысить актуальность клиентской информации.

#### Action

Я разработал сервисный слой для взаимодействия с CRM через **REST API**. Использовал **Spring WebClient** для HTTP-запросов и **MapStruct** для преобразования внутренних сущностей в DTO-модель, соответствующую контракту CRM. Добавил обработку ошибок и retry-механику для гарантированной доставки данных. Для аудита сохранял успешные и неуспешные синхронизации в таблицу `crm_sync_log` в PostgreSQL.

Пример кода:

```java
@Mapper(componentModel = "spring")
public interface CrmMapper {
    CrmStatusDto toDto(Shipment shipment);
}

@Service
public class CrmSyncService {
    private final WebClient client;
    private final CrmMapper mapper;

    public CrmSyncService(WebClient.Builder builder, CrmMapper mapper) {
        this.client = builder.baseUrl("https://internal-crm/api").build();
        this.mapper = mapper;
    }

    public void sync(Shipment shipment) {
        client.post()
              .uri("/status")
              .bodyValue(mapper.toDto(shipment))
              .retrieve()
              .toBodilessEntity()
              .block();
    }
}
```

#### Result

Интеграция позволила автоматически обновлять статусы клиентов в CRM без участия операторов. Скорость обработки информации увеличилась, а количество ошибок снизилось на **40%**, что улучшило качество обслуживания.
### Реализовал фильтрацию и сортировку треков по дате и статусу на уровне SQL
#### Situation

Клиенты получали список всех своих посылок в одном массиве без возможности сортировки и фильтрации. Это затрудняло поиск нужной информации и ухудшало пользовательский опыт.

#### Task

Необходимо было реализовать фильтрацию и сортировку треков по дате и статусу на стороне базы данных, чтобы повысить скорость выдачи и удобство работы в личном кабинете.

#### Action

Я добавил методы в репозиторий Spring Data JPA с использованием **Criteria API** и **Specifications**, чтобы формировать динамические запросы. На уровне PostgreSQL использовал индексы по колонкам `status` и `updated_at`. Это позволило выполнять выборку и сортировку прямо в SQL без лишней обработки на сервере.

Пример кода:

```java
public class ShipmentSpecifications {
    public static Specification<Shipment> hasStatus(String status) {
        return (root, query, cb) -> cb.equal(root.get("status"), status);
    }

    public static Specification<Shipment> updatedAfter(LocalDateTime date) {
        return (root, query, cb) -> cb.greaterThan(root.get("updatedAt"), date);
    }
}

List<Shipment> shipments = shipmentRepository.findAll(
        Specification.where(ShipmentSpecifications.hasStatus("IN_TRANSIT"))
                     .and(ShipmentSpecifications.updatedAfter(LocalDateTime.now().minusDays(7))),
        Sort.by(Sort.Direction.DESC, "updatedAt")
);
```

#### Result

Фильтрация и сортировка выполнялись напрямую в БД, что ускорило отклик системы на **35%**. Пользователи получили удобный инструмент поиска по статусу и дате, что повысило удовлетворённость и вовлечённость.
### Провёл рефакторинг кода в модуле работы с БД
#### Situation

Модуль работы с БД содержал дублирующиеся запросы, громоздкие методы и низкую читаемость. Это усложняло поддержку кода и увеличивало время на добавление новых функций.

#### Task

Необходимо было провести рефакторинг модуля работы с БД, чтобы уменьшить технический долг, повысить читаемость кода и упростить разработку новых запросов.

#### Action

Я вынес общую логику в **Spring Data JPA Specifications**, сократил дублирование кода и заменил «ручные» SQL-запросы на типобезопасные методы репозиториев. Добавил единый слой маппинга через DTO и MapStruct, что упростило передачу данных. Для сложных фильтров реализовал динамическое построение критериев через Criteria API.

Пример кода:

```java
public class ShipmentSpecifications {
    public static Specification<Shipment> byPhone(String phone) {
        return (root, query, cb) -> cb.equal(root.get("recipientPhone"), phone);
    }

    public static Specification<Shipment> byStatus(String status) {
        return (root, query, cb) -> cb.equal(root.get("status"), status);
    }
}

// использование
List<Shipment> shipments = shipmentRepository.findAll(
        Specification.where(ShipmentSpecifications.byPhone("79990001122"))
                     .and(ShipmentSpecifications.byStatus("IN_TRANSIT"))
);
```

#### Result

После рефакторинга код стал более компактным и читаемым. Команда могла быстрее реализовывать новые фильтры и запросы. Технический долг снизился, а количество багов, связанных с БД-запросами, уменьшилось примерно на **20%**.
### Внедрил автоматическое тестирование REST API
#### Situation

REST API покрывалось тестами частично и вручную. Это приводило к высоким рискам регрессий при изменениях и замедляло процесс выпуска новых версий.

#### Task

Необходимо было внедрить автоматическое тестирование REST API, чтобы повысить надёжность системы и сократить время проверки функционала.

#### Action

Я настроил тестирование на базе **JUnit 5**, **Spring Boot Test** и **Testcontainers**. Для каждого теста поднимался контейнер с PostgreSQL и Kafka, что обеспечивало изолированное окружение. Использовал `MockMvc` для проверки контроллеров и **REST Assured** для интеграционных сценариев. Дополнительно настроил GitLab CI, чтобы тесты выполнялись автоматически при каждом merge request.

Пример кода:

```java
@SpringBootTest
@AutoConfigureMockMvc
@Testcontainers
class ShipmentControllerTest {

    @Autowired
    private MockMvc mockMvc;

    @Test
    void shouldReturnShipmentByTrackingNumber() throws Exception {
        mockMvc.perform(get("/api/shipments/track/ABC123"))
               .andExpect(status().isOk())
               .andExpect(jsonPath("$.trackingNumber").value("ABC123"));
    }
}
```

#### Result

Покрытие тестами контроллеров и сервисов достигло **80%**. Это позволило находить ошибки ещё на стадии разработки, ускорило процесс code review и снизило количество багов на продакшене.
## Описание бизнесово-технических моментов
1. **Есть ли документация для интеграции с frontend и внешними API (если внешние API в этом проекте есть)?**
    

- Да, для интеграции с frontend использовался OpenAPI/Swagger 3.0.
    
- Для внешних API (DHL, Почта России) документация внешнего провайдера + внутренняя спецификация DTO и MapStruct-мэпперов.
    

2. **Какое git хранилище используется (Gitlab / Bitbucket)? Как устроены git-ветки (для фичей / мастер / develop)?**
    

- Использовался GitLab.
    
- Ветки: `master` (релизы), `develop` (интеграционная ветка для спринта), `feature/*` (отдельные фичи), `hotfix/*` для срочных исправлений.
    

3. **Как устроен код-ревью?**
    

- Все merge requests проходили peer-review минимум одного senior-разработчика.
    
- Использовались линтеры, статический анализ (SonarQube) и обязательное прохождение тестов.
    

4. **Есть ли тестовые стенды и как устроено тестирование (функциональное, интеграционное, нагрузочное)?**
    

- Стенды: dev, staging, production.
    
- Тестирование:
    
    - Unit-тесты (JUnit 5 + Mockito)
        
    - Интеграционные (Testcontainers для PostgreSQL/Kafka)
        
    - Нагрузочные тесты (JMeter/Gatling для пиковых сценариев)
        

5. **Как устроен CI/CD и кто за него отвечает?**
    

- GitLab CI/CD pipelines: сборка Maven → тесты → статический анализ → деплой на staging/prod.
    
- Ответственные: DevOps-инженеры + разработчики для тестирования пайплайнов.
    

6. **Как собирали и смотрели логи?**
    

- Логи собирались через SLF4J + Logback, централизованно аггрегировались в ELK/Graylog.
    
- Метки requestId для корреляции между сервисами.
    

7. **Как мониторили работоспособность системы (Grafana)?**
    

- Grafana + Prometheus для метрик (latency, обработка событий, потребление Kafka топиков, health endpoints).
    

8. **Какая пиковая и нормальная нагрузка на сервер?**
    

- **Нормальная:** ~500–1000 запросов в минуту на сервис Tracking.
    
- **Пиковая:** до 5000–7000 запросов в минуту, учитывая массовые обновления от внешних перевозчиков и уведомления клиентов.
    

---
# Второй проект 
## Дата трудоустройства - дата увольнения: 11.2023-н.в.
## Должность: Middle Developer
## Название компании: Точка Банк. Название проекта: Сервис начисления кэшбэка

## Описание проекта
### Описание проекта с точки зрения бизнеса:

Проект представляет собой сервис начисления кэшбэка для клиентов Точки Банка, рассчитанный на обработку транзакций в реальном времени с гибкой настройкой бизнес-правил. С точки зрения бизнеса команда состоит из трёх и более Java-разработчиков, системного аналитика, тестировщиков, DevOps-инженера, UI/UX-дизайнера и product owner’а. Взаимодействие с другими командами включает маркетинг (для промо-кампаний), аналитиков по данным и команду поддержки банковских продуктов. Разработка ведётся по Agile с использованием Scrum: спринты по 2 недели, ежедневные стендапы, планирование и ретроспективы. Главный заказчик — бизнес Точки Банка, конечный потребитель — клиенты банка, получающие кэшбэк. Задачи приходят от product owner’а и бизнес-аналитиков; часть формализована в виде технических заданий (ТЗ), часть в виде бизнес-требований (БТ) с описанием ожидаемого поведения и KPI. Такой подход обеспечивает быструю итеративную доставку функционала с возможностью адаптации под изменения рынка и требований клиентов.

### Описание проекта с точки зрения архитектуры:

#### Архитектура сервиса трекинга (system design) — подробное описание

Сервис построен как набор независимых микросервисов на Java 11 / Spring Boot, развёрнутых в контейнерах (Kubernetes). Центральная идея — CQRS-подобное разделение: операционная (OLTP) часть — в PostgreSQL, событийная шина — Apache Kafka для интеграций и асинхронной обработки, кэширование — Redis (для горячих запросов и rate-limiting). CI/CD + Testcontainers для интеграционных прогонов.

---

#### СУБД и основные сущности

**Основная СУБД:** PostgreSQL 13 — единый источник правды для бизнес-сущностей.

Примерная структура (≈12–15 таблиц):

- `clients` (B2B-клиенты, контактные данные)
    
- `users` (логины/роли операторов/клиентских админов)
    
- `shipments` / `parcels` (основная сущность отправления: id, external_track, client_id, status, created_at, estimated_delivery)
    
- `shipment_events` (история статусов: shipment_id, status, timestamp, source, payload)
    
- `recipients` / `addresses` (адреса, телефоны)
    
- `carriers` (DHL, Почта России и т.д.)
    
- `integrations_log` (запросы/ответы внешним API)
    
- `phone_index` (индекс для поиска по телефону)
    
- `audit_logs` (операции пользователей)
    
- `configs`, `retry_queue`, `dead_letters`
    

**Размеры (приблизительно, ориентир):**

- `shipments`: 1–10 M записей (зависит от объёма клиентов; для среднего оператора — ~3–5M).
    
- `shipment_events`: 10–50 M записей (каждому отправлению — несколько событий).
    
- `users`, `clients`, `carriers`: <<100k.  
    (Числа оценочные — в реальном проекте — метрики мониторинга и ретеншн задают точные значения.)
    

Дополнительно: **Redis** для кэширования последних состояний треков и сессий; TTL 10–60 минут. Для аналитики возможно выделение реплики PostgreSQL и ETL в отдельный хранилище (например, ClickHouse/OLAP) — данные из Kafka стримятся туда.

---

#### Kafka — топики и схема событий

Kafka используется как событийная шина для асинхронной интеграции, масштабируемой доставки событий и decoupling:

Основные топики:

- `tracking.events` — все изменения статусов (payload: shipment_id, status, timestamp, source).
    
- `tracking.commands` — команды на пересинхронизацию/получение состояния.
    
- `external.dhl.responses`, `external.post.responses` — ответы от интеграций с внешними перевозчиками (внутренние мапперы пишут в них).
    
- `crm.sync` — события для CRM (push статусов клиентов).
    
- `notifications.email`, `notifications.sms` — сообщения для нотификаций.
    
- `dead.letters` — ошибки обработки (DLQ).
    

Формат сообщений — JSON с версионированием в заголовке; при росте команда может ввести Avro + Schema Registry.

---

#### Микросервисы (перечень, взаимодействия и СУБД)

1. **API Gateway**
    
    - Тип: REST (Spring MVC).
        
    - Общается с: Auth, Tracking API (REST), Search (REST).
        
    - Роль: маршрутизация, auth, rate-limit, aggregation.
        
    - БД: нет (stateless).
      
2. **Auth & User Service**
    
    - REST для логина/ролей.
        
    - БД: `users` в PostgreSQL.
        
    - Причина REST: синхронный доступ для UI.
      
3. **Tracking Service (ядро)**
    
    - Обрабатывает запросы по трекам, CRUD отправлений, возвращает current state.
        
    - Общается: с PostgreSQL (shipments, shipment_events) напрямую; публикует события в Kafka `tracking.events` при изменениях; подписывается на `external.*` для обновлений от интеграций.
        
    - Почему: синхронный REST API для UI + асинхронная публикация для downstream.
    
4. **Integration Service (внешние API: DHL, Почта России)**
    
    - Подписан на `tracking.events` / `tracking.commands`; делает запросы к внешним перевозчикам через Spring WebClient; результаты публикует в `external.*` или напрямую в `tracking.events`.
        
    - Хранит логи в `integrations_log` (Postgres).
        
    - Почему Kafka: позволяет масштабировать опросы и повторную обработку, decouple.
    
5. **CRM Sync Service**
    
    - Подписчик `tracking.events`; шлёт агрегированные обновления в CRM через REST; записывает статусы отправки в `integrations_log`.
        
    - Почему: асинхронная интеграция — не блокировать основной поток.
      
6. **Notification Service**
    
    - Подписывается на `tracking.events`, пишет в `notifications.email` / `notifications.sms`; интегрируется с внешними провайдерами (REST).
        
    - Кэш шаблонов в Redis.
      
7. **Search / Query Service**
    
    - Предоставляет сложный поиск (по телефону, фильтры). Использует Spring Data JPA + Criteria API к PostgreSQL; кеширует горячие запросы в Redis.
        
    - Причина REST: быстрый sync отклик для UI.
      
8. **Analytics / ETL**
    
    - Читает `tracking.events` и стримит в OLAP (реплика Postgres / ClickHouse).
        
    - Вычисляет KPI, SLA, задержки.
      
9. **Admin / Batch Worker**
    
    - Обрабатывает retries, dead letters; запускает периодические jobs (например, reconciliation с перевозчиками). Работает через Kafka и DB.
      
---

#### Надёжность и масштабирование

- Идемпотентность: события содержат `event_id` и versioning.
    
- Retry и circuit-breaker: RetryTemplate и Resilience4j.
    
- Горизонтальное масштабирование: stateless-сервисы в K8s, Kafka consumer groups для параллелизма.
    
- Мониторинг: Prometheus + Grafana, лог-центризация (ELK/Graylog).
    

---
## Описание каждого микро-сервиса

### API Gateway / BFF

API Gateway / BFF — это фасад между клиентским приложением (веб/мобильный) и набором бэкенд-микросервисов. Его основная цель — упростить клиенту интерфейс, реализовать кросс-срезовую логику (аутентификация, агрегация, кеш, защиту) и выступать точкой входа для всех запросов.

Откуда берёт данные

- Прямо из внутренних микросервисов по REST (Tracking Service, Search, Auth, Notification, CRM).
    
- Асинхронно — через Kafka для событий/уведомлений (Gateway может подписываться на SSE/WebSocket-канал или получать push от Notification Service).
    
- Быстрые ответы из Redis (кеш последних статусов, сессии, rate counters).
    

Что делает внутри (функционал)

- Аутентификация/авторизация: проверка JWT/OAuth2 токенов (Spring Security), роль-менеджмент, scopes.
    
- Роутинг & трансформация: маршрутизация запросов к соответствующим сервисам, трансформация payload (API-versioning, адаптация полей для клиентов).
    
- Агрегация/композиция: объединяет ответы нескольких сервисов в один API-ответ (например: shipment + lastEvent + estimatedDelivery). Выполняет параллельные REST вызовы и собирает результат.
    
- Кеширование: ответные кеши в Redis с TTL для «горячих» треков; ETag/If-Modified-Since для снижения трафика.
    
- Rate limiting & throttling: token bucket / leaky bucket по API-ключам/пользователям.
    
- Resilience: circuit breaker, retry, fallback (Resilience4j).
    
- Валидация & контракт: входящий запрос валидируется по OpenAPI/JSON Schema; ошибки консолидируются.
    
- Логирование/трейсинг: OpenTelemetry/Zipkin, корреляция requestId, structured logs.
    
- Security hardening: input sanitization, CORS, CSP, IP whitelisting, WAF hooks.
    

Куда отправляет

- Синхронные REST-вызовы к соответствующим сервисам; агрегированные запросы параллельно.
    
- Публикует аналитические события (request/latency/errors) в Kafka/metrics pipeline.
    
- При push-уведомлениях использует WebSocket/SSE канал к клиентам (через Notification Service или напрямую, если BFF держит сессии).
    

Результат: единая, безопасная и производительная точка входа, минимизирующая сложность клиентской логики и уменьшающая число round-trip’ов.

### Auth & User Service
Auth & User Service — это центральный сервис аутентификации и управления пользователями, который обеспечивает безопасность всего трекинг-проекта. Он изолирован от других сервисов, но используется каждым при обращении через API Gateway.

Откуда берёт данные

- Основной источник — таблица `users` в PostgreSQL. Она содержит поля: `id`, `username`, `password_hash`, `email`, `phone`, `role`, `permissions`, `status`, `created_at`.
    
- Дополнительно сервис обращается к таблице `clients` (для B2B-аккаунтов и их администраторов).
    
- Для проверки токенов сессий и ограничения частоты запросов используется Redis (хранение refresh-токенов и blacklist).
    
- Для аудита сервис пишет записи в `audit_logs`.
    

Что делает внутри (функционал)

- **Регистрация/создание пользователей:** добавление новых B2B-клиентов или внутренних операторов. Пароли хэшируются через BCrypt.
    
- **Аутентификация:** проверка логина/пароля, генерация JWT (или OAuth2 access/refresh токенов).
    
- **Авторизация:** проверка ролей и прав доступа (например, клиент может видеть только свои посылки, оператор — все).
    
- **Управление ролями и правами:** выдача/отзыв прав, назначение админов, разграничение доступа по CRUD-операциям.
    
- **Сессии и токены:** хранение refresh-токенов в Redis, поддержка logout (через blacklist), автообновление access-токенов.
    
- **Безопасность:** защита от brute force (rate limiting), блокировка учётки после N неудачных входов, 2FA (через SMS/email сервисы).
    
- **Интеграция с внешними системами:** поддержка SSO (например, через OAuth2/OpenID Connect для корпоративных клиентов).
    
- **Аудит:** запись действий в PostgreSQL (`audit_logs`), логирование в Kafka для BI и мониторинга.
    

Куда отправляет

- Возвращает в API Gateway access/refresh токены.
    
- Передаёт в другие микросервисы сведения об аутентифицированном пользователе через JWT claims (id, role, clientId).
    
- В Kafka публикует события типа `user.created`, `user.blocked`, `user.roleChanged`.
    
- В `audit_logs` пишет действия пользователей (login, logout, изменение профиля).
    

**Итог:** сервис является ядром безопасности: проверяет идентичность, управляет ролями, ограничивает доступ и формирует событийный след для мониторинга.
### Tracking Service (ядро)
Tracking Service — это центральный микросервис системы, который отвечает за хранение и обработку всех данных, связанных с посылками и их статусами. Он является «источником истины» (system of record) для сущностей доставки и выступает основой для остальных сервисов.

Откуда берёт данные

- **PostgreSQL** — таблицы `shipments`, `shipment_events`, `recipients`, `addresses`. Именно здесь хранится текущее состояние и история каждой посылки.
    
- **Kafka** — топики `external.dhl.responses`, `external.post.responses`, откуда приходят новые статусы от Integration Service.
    
- **API Gateway** — получает REST-запросы от клиентов (через фронтенд или мобильное приложение).
    
- **Redis** — кэш последних статусов для ускорения выдачи популярных запросов.
    

Что делает внутри (функционал)

- **CRUD-операции над отправлениями:** создание записей о новых посылках, обновление информации, закрытие/удаление.
    
- **Обновление статусов:** получение новых событий (через Kafka), их валидация, сохранение в `shipment_events` и обновление «текущего статуса» в `shipments`.
    
- **Агрегация информации:** при запросе клиента сервис собирает данные о посылке, последнем статусе, прогнозируемой дате доставки и контактных данных получателя.
    
- **Поиск:** поддержка фильтров по дате, статусу, клиенту и поиск по телефону (через Criteria API).
    
- **Валидация и нормализация:** проверка формата данных, идемпотентность событий (по `event_id`), обработка конфликтов версий.
    
- **Бизнес-правила:** логика расчёта SLA, определение просрочек, формирование бизнес-ивентов (например, «посылка задержана»).
    
- **API-слой:** предоставляет REST-эндпоинты для BFF (например, `/shipments/{id}`, `/shipments/search`).
    

Куда отправляет

- **Kafka (`tracking.events`)** — публикация новых или обновлённых статусов, которые используются CRM, Notification Service и аналитикой.
    
- **PostgreSQL** — запись состояния и истории посылок.
    
- **API Gateway** — отдаёт REST-ответы клиентам (агрегированные данные по отправлению).
    
- **Redis** — обновляет кэш последних статусов.
    
- **Monitoring** — метрики по скорости обработки событий, количеству запросов, SLA-достижениям.
    

**Итог:** Tracking Service — ядро системы, в котором сходятся все потоки данных: клиенты читают из него статусы, интеграции пишут в него события, а остальные сервисы полагаются на его консистентность.
### Integration Service (внешние API: DHL, Почта России)
Integration Service отвечает за взаимодействие с внешними логистическими операторами (DHL, Почта России и др.) и является критическим звеном между внутренним ядром системы и внешними системами доставки. Он изолирует бизнес-логику от специфики интеграций, что упрощает поддержку и масштабирование.

Откуда берёт данные

- Подписывается на Kafka-топики `tracking.commands` (команды на обновление статусов) и `tracking.events` (новые внутренние события, требующие проверки у перевозчиков).
    
- Из PostgreSQL берёт настройки интеграций (`carriers`, `integrations_log`, retry-очередь).
    
- Может использовать Redis для временного хранения токенов/ключей доступа к внешним API.
    

Что делает внутри (функционал)

- **Обращение к внешним API:** выполняет REST-запросы к системам DHL и Почты России через Spring WebClient. Поддерживает авторизацию (API-ключи, OAuth2, токены).
    
- **Нормализация данных:** каждая система возвращает разный формат событий, поэтому сервис приводит их к унифицированной DTO-модели (MapStruct + internal schema).
    
- **Обработка ошибок:** реализованы retries (Spring Retry/RetryTemplate), отложенные запросы и circuit breaker (Resilience4j). При неудаче событие отправляется в `dead.letters`.
    
- **Логирование:** каждый вызов фиксируется в `integrations_log` (время, payload, статус). Это помогает как для отладки, так и для SLA-отчётов.
    
- **Идемпотентность:** события маркируются `external_event_id`, чтобы избежать повторной обработки одного и того же статуса.
    
- **Расписание:** сервис может запускать периодические batch-запросы (например, ночное обновление треков за последние 24 часа).
    

Куда отправляет

- В Kafka (`external.dhl.responses`, `external.post.responses`) публикует нормализованные ответы.
    
- В Kafka (`tracking.events`) отправляет новые статусы, пригодные для ядра Tracking Service.
    
- В PostgreSQL пишет логи вызовов и результаты в `integrations_log`.
    
- В Monitoring (Prometheus/Grafana) — метрики по SLA, ошибкам, задержкам.
    

**Итог:** Integration Service — связующее звено, которое берёт команды из системы, получает статусы у перевозчиков, нормализует их и передаёт в основной поток событий, гарантируя стабильность и единый формат данных.
### CRM Sync Service
CRM Sync Service — это специализированный микросервис, отвечающий за синхронизацию данных о статусах посылок с внутренней CRM-системой компании. Его задача — автоматизировать обновление клиентских карточек и устранить необходимость ручного ввода информации о доставках.

Откуда берёт данные

- **Kafka (`tracking.events`)** — основное место получения информации. Все изменения статусов посылок, зафиксированные в Tracking Service, транслируются сюда.
    
- **PostgreSQL (`integrations_log`)** — хранит историю синхронизаций и статусы их выполнения (успешно, ошибка, повторная попытка).
    
- **CRM API (внешнее)** — используется для валидации текущего состояния и проверки, требуется ли обновление.
    

Что делает внутри (функционал)

- **Подписка на события:** слушает Kafka-топики с новыми статусами.
    
- **Трансформация данных:** конвертирует событие в формат, который ожидает CRM (обычно REST DTO с полями `clientId`, `shipmentId`, `status`, `timestamp`).
    
- **Идемпотентность:** проверяет, не было ли уже отправлено событие с тем же идентификатором (`event_id`) в CRM, чтобы избежать дублирования.
    
- **Обработка ошибок:** при недоступности CRM сервис откладывает отправку и сохраняет задачу в retry-очередь; при превышении лимита попыток пишет событие в `dead.letters`.
    
- **Логирование:** фиксирует в `integrations_log` дату отправки, payload, результат (успех/ошибка).
    
- **Безопасность:** все запросы в CRM подписываются сервисным токеном/ключом.
    
- **Мониторинг SLA:** считает процент успешных синхронизаций и задержки между событием и записью в CRM.
    

Куда отправляет

- **CRM API:** отправляет обновления статусов и событий доставки (REST-запросы).
    
- **PostgreSQL:** сохраняет логи вызовов, результаты синхронизации и данные о retry.
    
- **Kafka (`crm.sync`)** — публикует события о результатах синхронизации (успех/ошибка) для последующего анализа и мониторинга.
    
- **Monitoring (Prometheus/Grafana):** метрики синхронизации и алерты о сбоях.
    

**Итог:** CRM Sync Service гарантирует, что CRM всегда отображает актуальные статусы посылок, облегчает работу менеджеров и повышает качество обслуживания клиентов.
### Notification Service
Notification Service — это микросервис, отвечающий за доставку уведомлений клиентам и получателям посылок. Его основная цель — обеспечить своевременное информирование о ключевых изменениях (новый статус, прибытие в сортировочный центр, доставка, задержка). Сервис поддерживает несколько каналов коммуникации: email, SMS, push-уведомления.

Откуда берёт данные

- **Kafka (`tracking.events`)** — основной источник, содержащий события об изменении статусов посылок.
    
- **PostgreSQL (`templates`, `notification_logs`)** — хранит шаблоны сообщений для разных каналов и историю отправок.
    
- **Redis** — используется для кэширования шаблонов и временных данных (например, частота уведомлений для одного получателя, чтобы избежать спама).
    
- **API Gateway / BFF** — запросы на ручную отправку уведомлений (например, подтверждение email или reset пароля).
    

Что делает внутри (функционал)

- **Подписка на события:** получает статусы о посылках, определяет, нужно ли уведомлять клиента (например, при смене статуса на «доставлено» или «задержка»).
    
- **Персонализация:** подставляет данные в шаблон (имя клиента, трек-номер, дата доставки).
    
- **Форматирование сообщений:** генерирует текст или HTML-письмо, готовит payload для SMS или push.
    
- **Канальная маршрутизация:** выбирает подходящий канал уведомления в зависимости от предпочтений клиента (email/SMS/push).
    
- **Обработка ошибок:** повторная отправка при сбое (RetryTemplate), запись в DLQ (`dead.letters`) при превышении лимита.
    
- **Логирование:** фиксирует все отправки в `notification_logs` с полями: `shipmentId`, `recipient`, `channel`, `status`, `timestamp`.
    
- **Rate limiting:** защита от избыточной рассылки (ограничение количества уведомлений в сутки для одного пользователя).
    

Куда отправляет

- **Внешние сервисы:**
    
    - Email-провайдер (SMTP/REST API).
        
    - SMS-шлюз (REST).
        
    - Push-сервисы (Firebase, APNS).
        
- **PostgreSQL:** запись истории уведомлений и статуса отправки.
    
- **Kafka (`notifications.email`, `notifications.sms`)** — публикация сообщений для дальнейшей обработки worker-подсистемами.
    
- **Monitoring (Prometheus/Grafana):** метрики по доставляемости, задержкам, ошибкам.
    

**Итог:** Notification Service автоматизирует информирование клиентов, снижает нагрузку на поддержку и повышает прозрачность логистики для конечных пользователей.
### Search / Query Service
Search Service — это микросервис, отвечающий за быстрый и удобный поиск посылок и связанных с ними данных. Его задача — предоставить пользователям (как клиентам, так и операторам) гибкий механизм поиска по различным параметрам: номеру трека, телефону получателя, дате отправки, статусу и другим критериям.

---

Откуда берёт данные

- **PostgreSQL** — основная база данных, таблицы `shipments`, `shipment_events`, `recipients`, `addresses`. Именно отсюда Search Service получает всю необходимую информацию.
    
- **Redis** — кэш для результатов частых поисковых запросов (например, повторные проверки одного и того же трек-номера).
    
- **Kafka (`tracking.events`)** — сервис подписан на поток событий, чтобы оперативно обновлять индексы поиска при изменении статуса посылки.
    

---

Что делает внутри (функционал)

- **Фильтрация и сортировка:** поддерживает поиск по дате, статусу, клиенту, телефону получателя. Использует Spring Data JPA + Criteria API для построения сложных запросов.
    
- **Поиск по телефону:** индексирует номера получателей в отдельной таблице (`phone_index`), что ускоряет выдачу при частых запросах без трек-номера.
    
- **Полнотекстовый поиск:** при необходимости использует расширения PostgreSQL (GIN/TSVector) для поиска по адресу или ФИО.
    
- **Агрегация:** возвращает вместе с результатом ключевые атрибуты посылки: последний статус, дату отправки, прогнозируемую дату доставки.
    
- **Кэширование:** сохраняет результаты популярных запросов в Redis (например, топ-10 последних посылок клиента).
    
- **Обновление индексов:** при поступлении новых событий из Kafka обновляет записи в БД и кэше, чтобы поиск всегда был актуальным.
    
- **Безопасность:** учитывает авторизацию пользователя (через JWT claims), ограничивая видимость данных (например, клиент видит только свои отправления).
    

---

Куда отправляет

- **API Gateway / BFF:** возвращает результаты поиска по REST в агрегированном виде для фронтенда.
    
- **PostgreSQL:** выполняет запросы и обновляет индексы.
    
- **Redis:** пишет и обновляет кэшированные результаты.
    
- **Monitoring:** публикует метрики поиска (время ответа, количество найденных записей, кэш-хиты).
    

---

**Итог:** Search Service обеспечивает быстрый, гибкий и безопасный доступ к данным о посылках. Благодаря индексации и кэшированию он выдерживает высокую нагрузку и ускоряет работу конечных пользователей.
### Analytics / ETL
Analytics / ETL Service — это микросервис (или связка сервисов), который отвечает за сбор, преобразование и загрузку данных из транзакционной части системы в аналитическое хранилище. Его основная цель — предоставить бизнесу актуальные отчёты и дашборды по доставке, SLA, загрузке курьеров и удовлетворённости клиентов.

---

Откуда берёт данные

- **Kafka (`tracking.events`)** — основной источник, содержащий все статусы посылок. Это поток событий, из которого ETL формирует аналитические витрины.
    
- **PostgreSQL (OLTP)** — таблицы `shipments`, `shipment_events`, `clients`, `carriers`. Используется для начальной загрузки и периодических сверок.
    
- **Integrations_log** — для анализа качества интеграций с внешними перевозчиками (ошибки, задержки).
    

---

Что делает внутри (функционал)

- **Extract (извлечение):** подписывается на Kafka и забирает все новые события о посылках. Дополнительно по расписанию выгружает «bulk-данные» из PostgreSQL (например, раз в сутки для проверки консистентности).
    
- **Transform (преобразование):**
    
    - Нормализует данные (объединяет статусы из разных перевозчиков в единый формат).
        
    - Добавляет бизнес-атрибуты (например, метка SLA — выполнено/не выполнено).
        
    - Агрегирует данные по клиентам, регионам, перевозчикам.
        
    - Обогащает данными о времени доставки, причинах задержек, количестве обращений в поддержку.
        
- **Load (загрузка):** пишет подготовленные данные в аналитическую СУБД (часто это **ClickHouse** или отдельная реплика PostgreSQL/Greenplum).
    
- **ETL-пайплайны:** выполняются батчево (ежедневная агрегация) и стримингово (почти реальное время).
    
- **Очистка и ретеншн:** удаляет устаревшие данные из промежуточных таблиц, архивирует сырые логи.
    

---

Куда отправляет

- **Аналитическое хранилище (ClickHouse / PostgreSQL-реплика):** для BI-систем и аналитических отчётов.
    
- **BI-платформы (Power BI, Grafana, Metabase):** дашборды для бизнеса (скорость доставки, SLA, топ клиентов, проблемные регионы).
    
- **Kafka (`analytics.reports`)** — публикация агрегированных событий (например, «доставлено с опозданием»).
    
- **Monitoring (Prometheus/Grafana):** метрики выполнения ETL (время обработки, количество загруженных записей, ошибки).
    

---

**Итог:** Analytics / ETL Service превращает поток «сырых» событий в структурированные аналитические данные. Он обеспечивает бизнес отчётами в реальном времени, помогает оценивать SLA и находить узкие места в логистике, что напрямую влияет на стратегические решения компании.

### Admin / Batch Worker
Admin / Batch Worker Service

Admin / Batch Worker — это служебный микросервис, который отвечает за выполнение фоновых задач, плановых джобов и административных операций в системе. Его главная роль — разгрузить ядро (Tracking Service) и интеграционные сервисы от тяжёлых или периодических вычислений, которые не требуют мгновенной реакции.

---

Откуда берёт данные

- **PostgreSQL** — таблицы `shipments`, `shipment_events`, `integrations_log`, `retry_queue`, `dead_letters`.
    
- **Kafka (`dead.letters`, `tracking.events`)** — подписывается на «проблемные» события для повторной обработки и сверки.
    
- **Конфигурации (configs)** — отдельная таблица в БД или YAML-файлы с расписаниями и настройками джобов.
    

---

Что делает внутри (функционал)

- **Retry обработка:** периодически проверяет `retry_queue` и `dead_letters`, повторно пытается отправить события в Tracking Service, CRM или Notification Service.
    
- **Batch-запросы:** раз в N часов запускает массовые сверки — например, проверяет все посылки в статусе «в пути» дольше 10 дней и запрашивает актуальный статус у перевозчика.
    
- **Архивация:** переносит устаревшие данные из `shipment_events` в архивные таблицы или внешнее хранилище, чтобы разгрузить OLTP.
    
- **Очистка данных:** удаляет временные записи, очищает кэш или старые retry-записи.
    
- **Мониторинг SLA:** формирует отчёты о задержках (например, «20% посылок клиента X просрочены»).
    
- **Админ-функции:** обработка ручных команд от операторов (например, «перезапустить синхронизацию для клиента А»).
    
- **Планировщик:** использует Quartz/Spring Scheduler для запуска джобов по cron-расписанию.
    
- **Resilience:** все операции выполняются с retry, логированием и идемпотентностью, чтобы избежать дубликатов.
    

---

Куда отправляет

- **Kafka (`tracking.events`, `crm.sync`, `notifications.*`)** — публикует результаты повторной обработки.
    
- **PostgreSQL (`integrations_log`, `audit_logs`)** — сохраняет отчёты о выполненных задачах.
    
- **Monitoring (Prometheus/Grafana):** отправляет метрики по статусу джобов (успешные/ошибки, время выполнения).
    
- **Админ-интерфейсы:** через REST API предоставляет операторам доступ к управлению задачами (например, повторный запуск).
    

---

**Итог:** Admin / Batch Worker Service обеспечивает «хозяйственную» часть системы — обрабатывает ошибки, повторно запускает процессы, чистит и архивирует данные. Он повышает надёжность всей архитектуры и снижает нагрузку на критичные микросервисы.

## Описание каждого достижения по STAR
### Реализовал личный кабинет клиента с возможностью отслеживания нескольких посылок одновременно.
#### Situation

Компания запускала личный кабинет для клиентов, но изначально там можно было проверять только одну посылку за раз. Это снижало удобство и заставляло пользователей уходить в сторонние сервисы.

#### Task

Необходимо было реализовать интерфейс и backend-логику, позволяющую клиенту авторизоваться и отслеживать сразу несколько посылок одновременно, с быстрым доступом к их статусам.

#### Action

Я разработал REST-контроллер в Spring MVC, который принимал список трек-номеров, обращался к БД через Spring Data JPA и возвращал агрегированный ответ. В PostgreSQL оптимизировал запросы с помощью `IN` и индексов по `tracking_number`. Для фронтенда — единый DTO со статусами.

Пример кода контроллера:

```java
@RestController
@RequestMapping("/api/shipments")
public class ShipmentController {
    private final ShipmentRepository shipmentRepository;

    public ShipmentController(ShipmentRepository shipmentRepository) {
        this.shipmentRepository = shipmentRepository;
    }

    @PostMapping("/track")
    public List<ShipmentDto> trackShipments(@RequestBody List<String> trackingNumbers) {
        return shipmentRepository.findByTrackingNumberIn(trackingNumbers)
                .stream()
                .map(ShipmentMapper::toDto)
                .toList();
    }
}
```

Репозиторий:

```java
public interface ShipmentRepository extends JpaRepository<Shipment, Long> {
    List<Shipment> findByTrackingNumberIn(List<String> trackingNumbers);
}
```

#### Result

Пользователи получили возможность отслеживать сразу несколько отправлений в личном кабинете. Среднее время сессии увеличилось на ~25%, снизилось количество уходов на сторонние трек-сервисы, что улучшило удержание клиентов.

---