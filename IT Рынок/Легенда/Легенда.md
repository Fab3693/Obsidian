# Первый проект (СДЭК)

## Описание проекта с точки зрения бизнеса:

Проект — корпоративный сервис трекинга посылок, ориентированный на B2B-клиентов и конечных получателей. Команда разработки состояла более чем из трёх Java-разработчиков, системного аналитика, frontend-инженера, инженера DevOps и QA-инженеров; при необходимости подключались интеграторы и техподдержка заказчика. Смежные команды включали продукт-менеджмент, службу поддержки, отдел интеграций (взаимодействие с DHL и Почтой России), аналитиков BI и маркетинга. Методология — Agile (Scrum) с двухнедельными спринтами, ежедневными стендапами, демо и ретроспективами; при ускорении задач использовался Kanban для оперативных инцидентов. Главный заказчик — коммерческий блок логистического партнёра/оператора, конечные потребители — клиенты и получатели посылок. Заявки на разработку обычно приходили от Product Owner и линейного бизнеса, требования формировались в виде бизнес-требований (БТ) с последующим ТЗ и acceptance-критериями от системного аналитика; срочные баг-репорты поступали от службы поддержки и SLA-партнёров. Взаимодействие с заказчиком включало регулярные план-показы, приоритетизацию roadmap и совместное согласование SLA; решения по масштабированию и отказоустойчивости принимались совместно с архитектором и бизнесом. Результатом стала повышенная точность статусов и удовлетворённость. Клиентов.

## Описание проекта с точки зрения архитектуры:

Архитектура сервиса трекинга (system design) — подробное описание

Сервис построен как набор независимых микросервисов на Java 11 / Spring Boot, развёрнутых в контейнерах (Kubernetes). Центральная идея — CQRS-подобное разделение: операционная (OLTP) часть — в PostgreSQL, событийная шина — Apache Kafka для интеграций и асинхронной обработки, кэширование — Redis (для горячих запросов и rate-limiting). CI/CD + Testcontainers для интеграционных прогонов.

---

СУБД и основные сущности

**Основная СУБД:** PostgreSQL 13 — единый источник правды для бизнес-сущностей.

Примерная структура (≈12–15 таблиц):

- `clients` (B2B-клиенты, контактные данные)
    
- `users` (логины/роли операторов/клиентских админов)
    
- `shipments` / `parcels` (основная сущность отправления: id, external_track, client_id, status, created_at, estimated_delivery)
    
- `shipment_events` (история статусов: shipment_id, status, timestamp, source, payload)
    
- `recipients` / `addresses` (адреса, телефоны)
    
- `carriers` (DHL, Почта России и т.д.)
    
- `integrations_log` (запросы/ответы внешним API)
    
- `phone_index` (индекс для поиска по телефону)
    
- `audit_logs` (операции пользователей)
    
- `configs`, `retry_queue`, `dead_letters`
    

**Размеры (приблизительно, ориентир):**

- `shipments`: 1–10 M записей (зависит от объёма клиентов; для среднего оператора — ~3–5M).
    
- `shipment_events`: 10–50 M записей (каждому отправлению — несколько событий).
    
- `users`, `clients`, `carriers`: <<100k.  
    (Числа оценочные — в реальном проекте — метрики мониторинга и ретеншн задают точные значения.)
    

Дополнительно: **Redis** для кэширования последних состояний треков и сессий; TTL 10–60 минут. Для аналитики возможно выделение реплики PostgreSQL и ETL в отдельный хранилище (например, ClickHouse/OLAP) — данные из Kafka стримятся туда.

---

Kafka — топики и схема событий

Kafka используется как событийная шина для асинхронной интеграции, масштабируемой доставки событий и decoupling:

Основные топики:

- `tracking.events` — все изменения статусов (payload: shipment_id, status, timestamp, source).
    
- `tracking.commands` — команды на пересинхронизацию/получение состояния.
    
- `external.dhl.responses`, `external.post.responses` — ответы от интеграций с внешними перевозчиками (внутренние мапперы пишут в них).
    
- `crm.sync` — события для CRM (push статусов клиентов).
    
- `notifications.email`, `notifications.sms` — сообщения для нотификаций.
    
- `dead.letters` — ошибки обработки (DLQ).
    

Формат сообщений — JSON с версионированием в заголовке; при росте команда может ввести Avro + Schema Registry.

---

Микросервисы (перечень, взаимодействия и СУБД)

1. **API Gateway**
    
    - Тип: REST (Spring MVC).
        
    - Общается с: Auth, Tracking API (REST), Search (REST).
        
    - Роль: маршрутизация, auth, rate-limit, aggregation.
        
    - БД: нет (stateless).
      
      [[API Gateway — подробности]]
    
2. **Auth & User Service**
    
    - REST для логина/ролей.
        
    - БД: `users` в PostgreSQL.
        
    - Причина REST: синхронный доступ для UI.
      
       [[Auth & User Service — подробности]]
    
1. **Tracking Service (ядро)**
    
    - Обрабатывает запросы по трекам, CRUD отправлений, возвращает current state.
        
    - Общается: с PostgreSQL (shipments, shipment_events) напрямую; публикует события в Kafka `tracking.events` при изменениях; подписывается на `external.*` для обновлений от интеграций.
        
    - Почему: синхронный REST API для UI + асинхронная публикация для downstream.
        
2. **Integration Service (внешние API: DHL, Почта России)**
    
    - Подписан на `tracking.events` / `tracking.commands`; делает запросы к внешним перевозчикам через Spring WebClient; результаты публикует в `external.*` или напрямую в `tracking.events`.
        
    - Хранит логи в `integrations_log` (Postgres).
        
    - Почему Kafka: позволяет масштабировать опросы и повторную обработку, decouple.
        
3. **CRM Sync Service**
    
    - Подписчик `tracking.events`; шлёт агрегированные обновления в CRM через REST; записывает статусы отправки в `integrations_log`.
        
    - Почему: асинхронная интеграция — не блокировать основной поток.
        
4. **Notification Service**
    
    - Подписывается на `tracking.events`, пишет в `notifications.email` / `notifications.sms`; интегрируется с внешними провайдерами (REST).
        
    - Кэш шаблонов в Redis.
        
5. **Search / Query Service**
    
    - Предоставляет сложный поиск (по телефону, фильтры). Использует Spring Data JPA + Criteria API к PostgreSQL; кеширует горячие запросы в Redis.
        
    - Причина REST: быстрый sync отклик для UI.
        
6. **Analytics / ETL**
    
    - Читает `tracking.events` и стримит в OLAP (реплика Postgres / ClickHouse).
        
    - Вычисляет KPI, SLA, задержки.
        
7. **Admin / Batch Worker**
    
    - Обрабатывает retries, dead letters; запускает периодические jobs (например, reconciliation с перевозчиками). Работает через Kafka и DB.
        

---

Надёжность и масштабирование

- Идемпотентность: события содержат `event_id` и versioning.
    
- Retry и circuit-breaker: RetryTemplate и Resilience4j.
    
- Горизонтальное масштабирование: stateless-сервисы в K8s, Kafka consumer groups для параллелизма.
    
- Мониторинг: Prometheus + Grafana, лог-центризация (ELK/Graylog).
    

---





# Второй проект (Точка Банк)
